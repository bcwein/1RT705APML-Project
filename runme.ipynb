{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.9.7",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.7 64-bit ('APML': conda)"
    },
    "interpreter": {
      "hash": "594dcc25420435e27a28c7a07c7809458f9c1b33c1ac2fc5f4ef141ae79a8e72"
    },
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/bcwein/1RT705APML-Project/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 5 A first Gibbs sampler\r\n",
        "\r\n",
        "Want to estimate posterior\r\n",
        "\r\n",
        "$$\r\n",
        "p(s_1, s_2|y=1)\r\n",
        "$$\r\n",
        "\r\n",
        "And we know that $p(y=1)$ = $p(t>0)$.\r\n",
        "\r\n",
        "so\r\n",
        "\r\n",
        "$$\r\n",
        "p(s_1, s_2|t>0)\r\n",
        "$$"
      ],
      "metadata": {
        "id": "G6GHhhdilHSb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project in APML\r\n",
        "\r\n",
        "Contributors:\r\n",
        "\r\n",
        "- BjÃ¸rn Christian Weinbach\r\n",
        "- Emil\r\n",
        "- Markus"
      ],
      "metadata": {
        "id": "xLeCco93lHSV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\r\n",
        "import scipy.stats\r\n",
        "import matplotlib.pyplot\r\n",
        "import seaborn as sns\r\n",
        "sns.set_style('darkgrid')\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "# Save figures - Set to true if you want to reproduce figures.\r\n",
        "save = False\r\n",
        "\r\n",
        "def gibbsSampler(L, mu_s, sigma_s, burn=0):\r\n",
        "    L = L\r\n",
        "\r\n",
        "    # Initial Chain of values\r\n",
        "    s1 = np.zeros(L)\r\n",
        "    s2 = np.zeros(L)\r\n",
        "    t = np.zeros(L)\r\n",
        "    y = 1\r\n",
        "    s1[0] = 10\r\n",
        "    s2[0] = 10\r\n",
        "    t[0] = 1\r\n",
        "\r\n",
        "    # Hyperparameters\r\n",
        "    sigma_s = sigma_s\r\n",
        "    mu_s = mu_s\r\n",
        "    sigma_ts = 1\r\n",
        "\r\n",
        "    def corr1(sigmaa, A, sigmaba, mua, xb): \r\n",
        "        sigmaab = np.linalg.pinv(np.linalg.pinv(sigmaa) + np.outer(A.T, A)*sigmaba**-1)\r\n",
        "        muab = sigmaab@(np.linalg.pinv(sigmaa)@mua + A.T*sigmaba**-1*xb)\r\n",
        "        return sigmaab, muab\r\n",
        "\r\n",
        "    for l in range(L-1):\r\n",
        "        # Sample S\r\n",
        "        A = np.array([s1[l], -s2[l]])\r\n",
        "        sigma_st, mu_st = corr1(sigma_s, A, sigma_ts, mu_s, t[l])\r\n",
        "        s1[l+1], s2[l+1] = scipy.stats.multivariate_normal.rvs(mean=mu_st, cov=sigma_st)\r\n",
        "\r\n",
        "        # Sample T\r\n",
        "        smean = s1[l] - s2[l]\r\n",
        "        a_scaled, b_scaled = (0 - (smean)) / sigma_ts, (np.inf - (smean)) / sigma_ts\r\n",
        "        t[l+1] = scipy.stats.truncnorm.rvs(a_scaled, b_scaled, loc=smean, scale=np.sqrt(sigma_ts))\r\n",
        "    return s1[burn:], s2[burn:], t[burn:]"
      ],
      "outputs": [],
      "metadata": {
        "id": "_SKDP9m9lHSd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Samples\r\n",
        "L = 10**4\r\n",
        "burn = 50\r\n",
        "# Priors\r\n",
        "sigma_s = np.array([[1, 0], [0, 1]])\r\n",
        "mu_s = np.array([1, 1])\r\n",
        "\r\n",
        "# Sample\r\n",
        "s1, s2, t = gibbsSampler(L+burn, mu_s, sigma_s, burn)"
      ],
      "outputs": [],
      "metadata": {
        "id": "1MI8qpEvlHSg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "experiment = pd.DataFrame(\r\n",
        "    {\r\n",
        "        \"s1\": s1,\r\n",
        "        \"s2\": s2,\r\n",
        "        \"t\": t\r\n",
        "    }\r\n",
        ")"
      ],
      "outputs": [],
      "metadata": {
        "id": "0KmLkZ9xlHSh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.plot(s1)\r\n",
        "if(save):\r\n",
        "    plt.savefig(\"s1traceplotwithoutburnin.png\")\r\n",
        "np.mean(s1)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "duuNBMq4lHSi",
        "outputId": "acb548ed-98d8-44e5-d3a2-f3f438ff034e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.plot(s2)\r\n",
        "if(save):\r\n",
        "    plt.savefig(\"s2traceplotwithoutburnin.png\")"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "u3iEM_NKlHSm",
        "outputId": "0430df9e-af03-4da6-8e30-b6535125689e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.figure(figsize=(15, 15))\r\n",
        "sns.set_style(\"darkgrid\")\r\n",
        "sns.jointplot(data=experiment, x=\"s1\", y=\"s2\",\r\n",
        "              xlim=(-3, 5), ylim=(-4, 4))\r\n",
        "\r\n",
        "if(save):\r\n",
        "    plt.savefig(\"s1s2jointplot.png\")"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "GNO6vIdllHSn",
        "outputId": "32807b7f-0e91-4857-ead6-ecc23ac79f02"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sns.histplot(experiment, x=\"t\", kde=True, fill=True, stat='probability')\r\n",
        "if(save):\r\n",
        "    plt.savefig(\"thistogram.png\")"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "kT3iKeTvlHSo",
        "outputId": "fcaaf5f7-f9f8-4c21-b49f-3b0b6eb214f3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trueskill representation of the skills\r\n",
        "\r\n",
        "We will transform the samples into a gaussian. We will do this by approximating it as a gaussian."
      ],
      "metadata": {
        "id": "gVMaL2OwlHSp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def gaussianApprox(samples):\r\n",
        "    return scipy.stats.norm(loc=np.mean(samples), scale=np.std(samples))\r\n",
        "\r\n",
        "s1gauss = gaussianApprox(experiment.s1)\r\n",
        "s2gauss = gaussianApprox(experiment.s2)\r\n",
        "\r\n",
        "approximation = pd.DataFrame(\r\n",
        "    {\r\n",
        "        \"s1gauss\" : s1gauss.rvs(L),\r\n",
        "        \"s2gauss\" : s2gauss.rvs(L),\r\n",
        "    }\r\n",
        ")\r\n",
        "\r\n",
        "sns.jointplot(data=approximation, x=\"s1gauss\", y=\"s2gauss\",\r\n",
        "              xlim=(-3, 5), ylim=(-4, 4))\r\n",
        "\r\n",
        "if(save):\r\n",
        "    plt.savefig(\"GaussApproxJointPlot.png\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "YP99Wx7KlHSq",
        "outputId": "2d008019-1896-4d7a-c7b2-263aff3cc0c2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.plot(approximation.s1gauss)\r\n",
        "if(save):\r\n",
        "    plt.savefig(\"s1GaussApproxTraceplot.png\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "2brakQNAlHSr",
        "outputId": "88cf8799-40b3-4cf0-a309-091fbfb84a14"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "plt.plot(approximation.s2gauss)\r\n",
        "if(save):\r\n",
        "    plt.savefig(\"s1GaussApproxTraceplot.png\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "CTaNoRzFlHSs",
        "outputId": "2db85378-4283-4d73-cd38-690dac1cbdaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot histogram of samples with fitted gaussians $L=10^4$"
      ],
      "metadata": {
        "id": "Z21VrI8OlHSt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Samples\r\n",
        "L = 10**4\r\n",
        "burn = 50\r\n",
        "# Priors\r\n",
        "sigma_s = np.array([[1, 0], [0, 1]])\r\n",
        "mu_s = np.array([1, 1])\r\n",
        "\r\n",
        "# Sample\r\n",
        "s1, s2, t = gibbsSampler(L+burn, mu_s, sigma_s, burn)"
      ],
      "outputs": [],
      "metadata": {
        "id": "5A5yLInJlHSt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "s1gauss = gaussianApprox(s1)\r\n",
        "x = np.linspace(-2, 5)\r\n",
        "plt.hist(s1, bins=30, density=True, label='Samples')\r\n",
        "plt.plot(x, s1gauss.pdf(x), label='Approximation')\r\n",
        "plt.legend()\r\n",
        "plt.title(\"$S_1$ samples vs approximation for $L =10^4$ samples\")\r\n",
        "if(save):\r\n",
        "    plt.savefig(\"s1samplevsdist10000.png\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "jx-t9TNclHSt",
        "outputId": "33b40082-f742-4502-beb3-5889a6d732b3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "s2gauss = gaussianApprox(s2)\r\n",
        "x = np.linspace(-2, 5)\r\n",
        "plt.hist(s2, bins=30, density=True, label='Samples')\r\n",
        "plt.plot(x, s2gauss.pdf(x), label='Approximation')\r\n",
        "plt.legend()\r\n",
        "plt.title(\"$S_2$ samples vs approximation for $L =10^4$ samples\")\r\n",
        "if(save):\r\n",
        "    plt.savefig(\"s2samplevsdist10000.png\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "_1ZgOI6ulHSt",
        "outputId": "d7a8fa84-f901-4ab7-af8f-337072276875"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot histogram of samples with fitted gaussians $L=10^3$"
      ],
      "metadata": {
        "id": "t5wma7f8lHSu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Samples\r\n",
        "L = 10**3\r\n",
        "burn = 50\r\n",
        "# Priors\r\n",
        "sigma_s = np.array([[1, 0], [0, 1]])\r\n",
        "mu_s = np.array([1, 1])\r\n",
        "\r\n",
        "# Sample\r\n",
        "s1, s2, t = gibbsSampler(L+burn, mu_s, sigma_s, burn)"
      ],
      "outputs": [],
      "metadata": {
        "id": "dZnkjWjSlHSu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "s1gauss = gaussianApprox(s1)\r\n",
        "x = np.linspace(-2, 5)\r\n",
        "plt.hist(s1, bins=30, density=True, label='Samples')\r\n",
        "plt.plot(x, s1gauss.pdf(x), label='Approximation')\r\n",
        "plt.legend()\r\n",
        "plt.title(\"$S_1$ samples vs approximation for $L =10^3$ samples\")\r\n",
        "if(save):\r\n",
        "    plt.savefig(\"s1samplevsdist1000.png\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "6xh7gVM9lHSv",
        "outputId": "433208d6-f0d6-4b9b-9f17-95e7359c50a9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "s2gauss = gaussianApprox(s2)\r\n",
        "x = np.linspace(-2, 5)\r\n",
        "plt.hist(s2, bins=30, density=True, label='Samples')\r\n",
        "plt.plot(x, s2gauss.pdf(x), label='Approximation')\r\n",
        "plt.legend()\r\n",
        "plt.title(\"$S_2$ samples vs approximation for $L =10^3$ samples\")\r\n",
        "if(save):\r\n",
        "    plt.savefig(\"s2samplevsdist1000.png\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "qejYohtUlHSv",
        "outputId": "bb1b0bdd-c830-43f0-ad8d-01d94148040a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot histogram of samples with fitted gaussians $L=100$"
      ],
      "metadata": {
        "id": "P1vKtZ8TlHSw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Samples\r\n",
        "L = 100\r\n",
        "burn = 50\r\n",
        "# Priors\r\n",
        "sigma_s = np.array([[1, 0], [0, 1]])\r\n",
        "mu_s = np.array([1, 1])\r\n",
        "\r\n",
        "# Sample\r\n",
        "s1, s2, t = gibbsSampler(L+burn, mu_s, sigma_s, burn)"
      ],
      "outputs": [],
      "metadata": {
        "id": "p3FIjxTdlHSw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "s1gauss = gaussianApprox(s1)\r\n",
        "x = np.linspace(-2, 5)\r\n",
        "plt.hist(s1, bins=30, density=True, label='Samples')\r\n",
        "plt.plot(x, s1gauss.pdf(x), label='Approximation')\r\n",
        "plt.legend()\r\n",
        "plt.title(\"$S_1$ samples vs approximation for $L =100$ samples\")\r\n",
        "if(save):\r\n",
        "    plt.savefig(\"s1samplevsdist100.png\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "TdIT8-d8lHSw",
        "outputId": "097fb13d-aab7-47ad-f031-51827b9e2903"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "s2gauss = gaussianApprox(s2)\r\n",
        "x = np.linspace(-2, 5)\r\n",
        "plt.hist(s1, bins=30, density=True, label='Samples')\r\n",
        "plt.plot(x, s1gauss.pdf(x), label='Approximation')\r\n",
        "plt.legend()\r\n",
        "plt.title(\"$S_1$ samples vs approximation for $L =100$ samples\")\r\n",
        "if(save):\r\n",
        "    plt.savefig(\"s2samplevsdist100.png\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "B4eBLUw-lHSx",
        "outputId": "7835b1e3-302d-4c23-dca4-197a173ca9b1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot histogram of samples with fitted gaussians $L=30$"
      ],
      "metadata": {
        "id": "eiM8NYNolHSy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Samples\r\n",
        "L = 30\r\n",
        "burn = 50\r\n",
        "# Priors\r\n",
        "sigma_s = np.array([[1, 0], [0, 1]])\r\n",
        "mu_s = np.array([1, 1])\r\n",
        "\r\n",
        "# Sample\r\n",
        "s1, s2, t = gibbsSampler(L+burn, mu_s, sigma_s, burn)"
      ],
      "outputs": [],
      "metadata": {
        "id": "VC-RxpkxlHSy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "s1gauss = gaussianApprox(s1)\r\n",
        "x = np.linspace(-2, 5)\r\n",
        "plt.hist(s1, bins=30, density=True, label='Samples')\r\n",
        "plt.plot(x, s1gauss.pdf(x), label='Approximation')\r\n",
        "plt.legend()\r\n",
        "plt.title(\"$S_1$ samples vs approximation for $L =30$ samples\")\r\n",
        "if(save):\r\n",
        "    plt.savefig(\"s1samplevsdist30.png\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "MDHUOAjvlHSy",
        "outputId": "36ce4850-56d9-485c-f735-11b7d2457578"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "s2gauss = gaussianApprox(s2)\r\n",
        "x = np.linspace(-2, 5)\r\n",
        "plt.hist(s2, bins=30, density=True, label='Samples')\r\n",
        "plt.plot(x, s1gauss.pdf(x), label='Approximation')\r\n",
        "plt.legend()\r\n",
        "plt.title(\"$S_1$ samples vs approximation for $L =30$ samples\")\r\n",
        "if(save):\r\n",
        "    plt.savefig(\"s2samplevsdist30.png\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "DmZOf0QilHSy",
        "outputId": "684c5031-fe8a-45c4-f03e-c993e063db11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare priors with posteriors given thet $p(s|y=1)$\n",
        "\n",
        "Our prior stated:\n",
        "\n",
        "$$\n",
        "p(s_1) = \\sim N(s_1; 1, 1)\n",
        "$$\n",
        "\n",
        "$$\n",
        "p(s_2) = \\sim N(s_2; 1, 1)\n",
        "$$\n",
        "\n",
        "Empirically we have:"
      ],
      "metadata": {
        "id": "lDTJKWYYlHS0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "np.mean(s1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "9yzxTOIXlHS0",
        "outputId": "e779cdfe-b993-4096-f61e-c17720076fee"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "np.var(s1)"
      ],
      "outputs": [],
      "metadata": {
        "id": "VnFb-3tklHS0",
        "outputId": "b2b49297-bf7b-4148-e868-e9bf528e1bfc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "np.mean(s2)"
      ],
      "outputs": [],
      "metadata": {
        "id": "VPr-qeuolHS0",
        "outputId": "93754161-084f-43d2-bd42-c689d31b1f8c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "np.var(s2)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Qd-a2J_UlHS0",
        "outputId": "e376a12d-ff52-42fa-cb9c-138752310644"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 6\r\n",
        "\r\n",
        "Use ADF with Gibbs sampling to process the matches in theSerieAdataset and estimatethe skill of all the teams in the dataset "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Read the data\r\n",
        "data = 'datasets/SerieA.csv'\r\n",
        "shuffle = True\r\n",
        "serieA = pd.read_csv(data)\r\n",
        "cleaned = serieA[serieA['score1'] != serieA['score2']]\r\n",
        "cleaned[\"pred\"] = 0\r\n",
        "cleaned['true'] = np.where(cleaned['score1'] > cleaned['score2'], 1, -1)\r\n",
        "if(shuffle):\r\n",
        "    cleaned = cleaned.sample(frac=1).reset_index(drop=True)\r\n",
        "cleaned"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add priors to all teams"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# hyperparameters\r\n",
        "L = 100\r\n",
        "burn = 50\r\n",
        "# Priors\r\n",
        "sigma_s = np.array([[1, 0], [0, 1]], dtype=np.float64)\r\n",
        "mu_s = np.array([1, 1], dtype=np.float64)\r\n",
        "\r\n",
        "# Sample\r\n",
        "s1, s2, t = gibbsSampler(L+burn, mu_s, sigma_s, burn)\r\n",
        "s1gauss = gaussianApprox(s1)\r\n",
        "s2gauss = gaussianApprox(s2)\r\n",
        "teams = cleaned.team1.unique()\r\n",
        "\r\n",
        "# Make dictionary of priors\r\n",
        "distributions = {}\r\n",
        "\r\n",
        "# Give all same prior\r\n",
        "for team in teams:\r\n",
        "    distributions[team] = s1gauss"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Update distributions based on data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Update priors based on data\r\n",
        "for index, row in cleaned.iterrows():\r\n",
        "    if row['score1'] > row['score2']:\r\n",
        "        # Team 1 won\r\n",
        "        mu1 = distributions[row['team1']].mean()\r\n",
        "        mu2 = distributions[row['team2']].mean()\r\n",
        "        s1 = distributions[row['team1']].var()\r\n",
        "        s2 = distributions[row['team2']].var()\r\n",
        "\r\n",
        "        mu_s = np.array([mu1, mu2], np.float64)\r\n",
        "        sigma_s = np.array([[s1, 0], [0, s2]], dtype=np.float64)\r\n",
        "\r\n",
        "        # Sample\r\n",
        "        s1, s2, t = gibbsSampler(L+burn, mu_s, sigma_s, burn)\r\n",
        "        s1gauss = gaussianApprox(s1)\r\n",
        "        s2gauss = gaussianApprox(s2)\r\n",
        "        distributions[row['team1']] = s1gauss\r\n",
        "        distributions[row['team2']] = s2gauss\r\n",
        "\r\n",
        "    else:\r\n",
        "        # Team 2 won\r\n",
        "        mu1 = distributions[row['team2']].mean()\r\n",
        "        mu2 = distributions[row['team1']].mean()\r\n",
        "        s1 = distributions[row['team2']].var()\r\n",
        "        s2 = distributions[row['team1']].var()\r\n",
        "\r\n",
        "        mu_s = np.array([mu1, mu2], np.float64)\r\n",
        "        sigma_s = np.array([[s1, 0], [0, s2]], dtype=np.float64)\r\n",
        "\r\n",
        "        # Sample\r\n",
        "        s1, s2, t = gibbsSampler(L+burn, mu_s, sigma_s, burn)\r\n",
        "        s1gauss = gaussianApprox(s1)\r\n",
        "        s2gauss = gaussianApprox(s2)\r\n",
        "        distributions[row['team2']] = s1gauss\r\n",
        "        distributions[row['team1']] = s2gauss\r\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a ranking table that ranks based on trueskill's conservative skill with $k=3$"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "team, cs = [], []\r\n",
        "k = 3\r\n",
        "\r\n",
        "for key, dist in distributions.items():\r\n",
        "    team.append(key)\r\n",
        "    cs.append(dist.mean() - k*dist.std())\r\n",
        "\r\n",
        "results = pd.DataFrame(\r\n",
        "    {\r\n",
        "        'Team': team,\r\n",
        "        'Conservative Skill': cs\r\n",
        "    }\r\n",
        ")\r\n",
        "results = results.sort_values('Conservative Skill', ascending=False).reset_index(drop=True)\r\n",
        "results"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "x = np.linspace(-5, 5, 500)\r\n",
        "\r\n",
        "plt.figure(figsize=(15, 10))\r\n",
        "\r\n",
        "for key, dist in distributions.items():\r\n",
        "    plt.plot(x, dist.pdf(x), label=key)\r\n",
        "\r\n",
        "plt.legend()\r\n",
        "plt.title(\"Posterior of all teams\")\r\n",
        "if(save):\r\n",
        "    plt.savefig(\"posteriors.png\")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q7 Using the model for predictions\r\n",
        "\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def winningPrediction(player1, player2, k=3):\r\n",
        "    m1, m2 = distributions[player1].mean(), distributions[player2].mean()\r\n",
        "    s1, s2 = distributions[player1].std(), distributions[player2].std()\r\n",
        "    cs1, cs2 = m1 - k*s1, m2 - k*s2\r\n",
        "    if(cs1 >= cs2):\r\n",
        "      return 1\r\n",
        "    else:\r\n",
        "      return -1"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reset Priors"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# hyperparameters\r\n",
        "L = 100\r\n",
        "burn = 50\r\n",
        "\r\n",
        "# Priors\r\n",
        "sigma_s = np.array([[1, 0], [0, 1]], dtype=np.float64)\r\n",
        "mu_s = np.array([1, 1], dtype=np.float64)\r\n",
        "\r\n",
        "# Sample\r\n",
        "s1, s2, t = gibbsSampler(L+burn, mu_s, sigma_s, burn)\r\n",
        "s1gauss = gaussianApprox(s1)\r\n",
        "s2gauss = gaussianApprox(s2)\r\n",
        "teams = cleaned.team1.unique()\r\n",
        "\r\n",
        "# Make dictionary of priors\r\n",
        "distributions = {}\r\n",
        "\r\n",
        "# Give all same prior\r\n",
        "for team in teams:\r\n",
        "    distributions[team] = s1gauss"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate posterior and predict one step ahead"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pred = []\r\n",
        "\r\n",
        "# Update priors based on data\r\n",
        "for index, row in cleaned.iterrows():\r\n",
        "    if row['score1'] > row['score2']:\r\n",
        "        # Team 1 won\r\n",
        "        mu1 = distributions[row['team1']].mean()\r\n",
        "        mu2 = distributions[row['team2']].mean()\r\n",
        "        s1 = distributions[row['team1']].var()\r\n",
        "        s2 = distributions[row['team2']].var()\r\n",
        "\r\n",
        "        pred.append(winningPrediction(row['team1'], row['team2']))\r\n",
        "\r\n",
        "        mu_s = np.array([mu1, mu2], np.float64)\r\n",
        "        sigma_s = np.array([[s1, 0], [0, s2]], dtype=np.float64)\r\n",
        "\r\n",
        "        # Sample\r\n",
        "        s1, s2, t = gibbsSampler(L+burn, mu_s, sigma_s, burn)\r\n",
        "        s1gauss = gaussianApprox(s1)\r\n",
        "        s2gauss = gaussianApprox(s2)\r\n",
        "        distributions[row['team1']] = s1gauss\r\n",
        "        distributions[row['team2']] = s2gauss\r\n",
        "\r\n",
        "    else:\r\n",
        "        # Team 2 won\r\n",
        "        mu1 = distributions[row['team2']].mean()\r\n",
        "        mu2 = distributions[row['team1']].mean()\r\n",
        "        s1 = distributions[row['team2']].var()\r\n",
        "        s2 = distributions[row['team1']].var()\r\n",
        "\r\n",
        "        pred.append(winningPrediction(row['team1'], row['team2']))\r\n",
        "\r\n",
        "        mu_s = np.array([mu1, mu2], np.float64)\r\n",
        "        sigma_s = np.array([[s1, 0], [0, s2]], dtype=np.float64)\r\n",
        "\r\n",
        "        # Sample\r\n",
        "        s1, s2, t = gibbsSampler(L+burn, mu_s, sigma_s, burn)\r\n",
        "        s1gauss = gaussianApprox(s1)\r\n",
        "        s2gauss = gaussianApprox(s2)\r\n",
        "        distributions[row['team2']] = s1gauss\r\n",
        "        distributions[row['team1']] = s2gauss\r\n",
        "\r\n",
        "cleaned[\"pred\"] = pred"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "true_values = np.array(cleaned.true)\r\n",
        "predictions = np.array(cleaned.pred)\r\n",
        "np.sum(true_values == predictions) / len(true_values)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 10. Tennis datasets\r\n",
        "\r\n",
        "I have downloaded the tennis dataset from [ATP Wourld Tour tennis data](https://datahub.io/sports-data/atp-world-tour-tennis-data).\r\n",
        "Let us explore this data and clean it up."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tennis = pd.read_csv('datasets/tennis.csv')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore the features"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tennis.columns"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Hyperparameters\r\n",
        "N = 15      # No of top winners we want to include\r\n",
        "Y = 2015    # Start year (inclusive)\r\n",
        "\r\n",
        "# Extract relevant features\r\n",
        "features = ['tourney_year_id', 'winner_name', 'loser_name']\r\n",
        "tennis = tennis[features]\r\n",
        "\r\n",
        "if(tennis.tourney_year_id.dtype == 'object'):\r\n",
        "    # convert to years  \r\n",
        "    tennis['tourney_year_id'] = tennis['tourney_year_id'].apply(lambda x : x.split('-')[0])\r\n",
        "    tennis['tourney_year_id'] = tennis['tourney_year_id'].astype(int)\r\n",
        "\r\n",
        "# Extract the latest years\r\n",
        "tennis = tennis[tennis.tourney_year_id >= Y]\r\n",
        "\r\n",
        "# Extract the 15 players who won the most matches\r\n",
        "winners = tennis.winner_name.value_counts()[:N].index.to_list()\r\n",
        "\r\n",
        "# Extract matches where these players are playing eachother\r\n",
        "topplayers = tennis[tennis.winner_name.isin(winners) & tennis.loser_name.isin(winners)]\r\n",
        "\r\n",
        "# Add prediction column\r\n",
        "topplayers[\"pred\"] = 0"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Gibbs sampler on data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# hyperparameters\r\n",
        "L = 100\r\n",
        "burn = 50\r\n",
        "# Priors\r\n",
        "sigma_s = np.array([[1, 0], [0, 1]], dtype=np.float64)\r\n",
        "mu_s = np.array([1, -1], dtype=np.float64)\r\n",
        "\r\n",
        "# Sample\r\n",
        "s1, s2, t = gibbsSampler(L+burn, mu_s, sigma_s, burn)\r\n",
        "s1gauss = gaussianApprox(s1)\r\n",
        "s2gauss = gaussianApprox(s2)\r\n",
        "\r\n",
        "# Make dictionary of priors\r\n",
        "distributions = {}\r\n",
        "\r\n",
        "# Give all same prior\r\n",
        "for player in winners:\r\n",
        "    distributions[player] = s1gauss"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pred = []\r\n",
        "\r\n",
        "# Update priors based on data\r\n",
        "for index, row in topplayers.iterrows():\r\n",
        "    pred.append(winningPrediction(row['winner_name'], row['loser_name']))\r\n",
        "    mu1 = distributions[row['winner_name']].mean()\r\n",
        "    mu2 = distributions[row['loser_name']].mean()\r\n",
        "    s1 = distributions[row['winner_name']].var()\r\n",
        "    s2 = distributions[row['loser_name']].var()\r\n",
        "\r\n",
        "    mu_s = np.array([mu1, mu2], np.float64)\r\n",
        "    sigma_s = np.array([[s1, 0], [0, s2]], dtype=np.float64)\r\n",
        "\r\n",
        "    # Sample\r\n",
        "    s1, s2, t = gibbsSampler(L+burn, mu_s, sigma_s, burn)\r\n",
        "    s1gauss = gaussianApprox(s1)\r\n",
        "    s2gauss = gaussianApprox(s2)\r\n",
        "    distributions[row['winner_name']] = s1gauss\r\n",
        "    distributions[row['loser_name']] = s2gauss\r\n",
        "\r\n",
        "topplayers[\"pred\"] = pred"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "x = np.linspace(-2, 2, 500)\r\n",
        "\r\n",
        "plt.figure(figsize=(15, 10))\r\n",
        "\r\n",
        "for key, dist in distributions.items():\r\n",
        "    plt.plot(x, dist.pdf(x), label=key)\r\n",
        "\r\n",
        "plt.legend()\r\n",
        "plt.title(\"Posterior of all players\")\r\n",
        "if(save):\r\n",
        "    plt.savefig(\"posteriors.png\")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "team, cs = [], []\r\n",
        "k = 3\r\n",
        "\r\n",
        "for key, dist in distributions.items():\r\n",
        "    team.append(key)\r\n",
        "    cs.append(dist.mean() - k*dist.std())\r\n",
        "\r\n",
        "results = pd.DataFrame(\r\n",
        "    {\r\n",
        "        'Team': team,\r\n",
        "        'Conservative Skill': cs\r\n",
        "    }\r\n",
        ")\r\n",
        "results = results.sort_values('Conservative Skill', ascending=False).reset_index(drop=True)\r\n",
        "results"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "predictions = np.array(topplayers['pred'])\r\n",
        "\r\n",
        "print(\"Accuray: \" + str(np.sum(predictions==1) / len(predictions)))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q11 Extensions of model\r\n",
        "\r\n",
        "Include draws:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def winningPrediction(player1, player2, k=3, drawprob=0.5):\r\n",
        "    m1, m2 = distributions[player1].mean(), distributions[player2].mean()\r\n",
        "    s1, s2 = distributions[player1].std(), distributions[player2].std()\r\n",
        "\r\n",
        "    # Draw update\r\n",
        "    beta = ((s1+s2)/4)**2\r\n",
        "    margin = np.abs(mu1 - mu2)\r\n",
        "    epsilon = scipy.stats.norm.ppf((drawprob + 1)/2)*np.sqrt(2)*beta\r\n",
        "\r\n",
        "    # Check if inside draw margin.\r\n",
        "    if(margin < epsilon):\r\n",
        "      return 0\r\n",
        "\r\n",
        "    cs1, cs2 = m1 - k*s1, m2 - k*s2\r\n",
        "    if(cs1 >= cs2):\r\n",
        "      return 1\r\n",
        "    else:\r\n",
        "      return -1"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Read the data\r\n",
        "data = 'datasets/SerieA.csv'\r\n",
        "shuffle = False\r\n",
        "serieA = pd.read_csv(data)\r\n",
        "cleaned = serieA\r\n",
        "cleaned[\"pred\"] = 0\r\n",
        "cleaned['true'] = np.sign(cleaned['score1'] - cleaned['score2'])\r\n",
        "if(shuffle):\r\n",
        "    cleaned = cleaned.sample(frac=1).reset_index(drop=True)\r\n",
        "cleaned"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# hyperparameters\r\n",
        "L = 100\r\n",
        "burn = 50\r\n",
        "# Priors\r\n",
        "sigma_s = np.array([[1, 0], [0, 1]], dtype=np.float64)\r\n",
        "mu_s = np.array([1, -1], dtype=np.float64)\r\n",
        "\r\n",
        "# Sample\r\n",
        "s1, s2, t = gibbsSampler(L+burn, mu_s, sigma_s, burn)\r\n",
        "s1gauss = gaussianApprox(s1)\r\n",
        "s2gauss = gaussianApprox(s2)\r\n",
        "\r\n",
        "# Make dictionary of priors\r\n",
        "distributions = {}\r\n",
        "\r\n",
        "# Give all same prior\r\n",
        "for player in teams:\r\n",
        "    distributions[player] = s1gauss"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pred = []\r\n",
        "drawprob = 0.5\r\n",
        "\r\n",
        "# Update priors based on data\r\n",
        "for index, row in cleaned.iterrows():\r\n",
        "    if row['score1'] > row['score2']:\r\n",
        "        # Team 1 won\r\n",
        "        mu1 = distributions[row['team1']].mean()\r\n",
        "        mu2 = distributions[row['team2']].mean()\r\n",
        "        s1 = distributions[row['team1']].var()\r\n",
        "        s2 = distributions[row['team2']].var()\r\n",
        "\r\n",
        "        pred.append(winningPrediction(row['team1'], row['team2'], drawprob))\r\n",
        "\r\n",
        "        mu_s = np.array([mu1, mu2], np.float64)\r\n",
        "        sigma_s = np.array([[s1, 0], [0, s2]], dtype=np.float64)\r\n",
        "\r\n",
        "        # Sample\r\n",
        "        s1, s2, t = gibbsSampler(L+burn, mu_s, sigma_s, burn)\r\n",
        "        s1gauss = gaussianApprox(s1)\r\n",
        "        s2gauss = gaussianApprox(s2)\r\n",
        "        distributions[row['team1']] = s1gauss\r\n",
        "        distributions[row['team2']] = s2gauss\r\n",
        "\r\n",
        "    elif row['score1'] < row['score2']:\r\n",
        "        # Team 2 won\r\n",
        "        mu1 = distributions[row['team2']].mean()\r\n",
        "        mu2 = distributions[row['team1']].mean()\r\n",
        "        s1 = distributions[row['team2']].var()\r\n",
        "        s2 = distributions[row['team1']].var()\r\n",
        "\r\n",
        "        pred.append(winningPrediction(row['team1'], row['team2'], drawprob))\r\n",
        "\r\n",
        "        mu_s = np.array([mu1, mu2], np.float64)\r\n",
        "        sigma_s = np.array([[s1, 0], [0, s2]], dtype=np.float64)\r\n",
        "\r\n",
        "        # Sample\r\n",
        "        s1, s2, t = gibbsSampler(L+burn, mu_s, sigma_s, burn)\r\n",
        "        s1gauss = gaussianApprox(s1)\r\n",
        "        s2gauss = gaussianApprox(s2)\r\n",
        "        distributions[row['team2']] = s1gauss\r\n",
        "        distributions[row['team1']] = s2gauss\r\n",
        "    else:\r\n",
        "        # We have a draw\r\n",
        "        mu1 = distributions[row['team1']].mean()\r\n",
        "        mu2 = distributions[row['team2']].mean()\r\n",
        "\r\n",
        "        # NB: Standard deviation in this case\r\n",
        "        s1 = distributions[row['team1']].std()\r\n",
        "        s2 = distributions[row['team2']].std()\r\n",
        "\r\n",
        "        pred.append(winningPrediction(row['team1'], row['team2'], drawprob))\r\n",
        "\r\n",
        "        # Draw update\r\n",
        "        beta = ((s1+s2)/4)**2\r\n",
        "        margin = np.abs(mu1 - mu2)\r\n",
        "        epsilon = scipy.stats.norm.ppf((drawprob + 1)/2)*np.sqrt(2)*beta\r\n",
        "\r\n",
        "        # Check if inside draw margin.\r\n",
        "        if(margin < epsilon):\r\n",
        "            if(mu1 > mu2):\r\n",
        "                # Punish player 1\r\n",
        "                newmu1 = mu1 - margin/s1\r\n",
        "                distributions[row['team1']] = scipy.stats.norm(loc=newmu1, scale=s1)\r\n",
        "                # Reward player 2\r\n",
        "                newmu2 = mu2 + margin/s2\r\n",
        "                distributions[row['team1']] = scipy.stats.norm(loc=newmu2, scale=s2)\r\n",
        "            if(mu2 > mu1):\r\n",
        "                # Reward player 1\r\n",
        "                newmu1 = mu1 + margin/s1\r\n",
        "                distributions[row['team1']] = scipy.stats.norm(loc=newmu1, scale=s1)\r\n",
        "                # Punish player 2\r\n",
        "                newmu2 = mu2 - margin/s2\r\n",
        "                distributions[row['team1']] = scipy.stats.norm(loc=newmu2, scale=s2)\r\n",
        "\r\n",
        "cleaned[\"pred\"] = pred"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "cleaned.pred.value_counts()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "x = np.linspace(-5, 5, 500)\r\n",
        "\r\n",
        "plt.figure(figsize=(15, 10))\r\n",
        "\r\n",
        "for key, dist in distributions.items():\r\n",
        "    plt.plot(x, dist.pdf(x), label=key)\r\n",
        "\r\n",
        "plt.legend()\r\n",
        "plt.title(\"Posterior of all players\")\r\n",
        "if(save):\r\n",
        "    plt.savefig(\"posteriors.png\")\r\n",
        "\r\n",
        "true_values = np.array(cleaned.true)\r\n",
        "predictions = np.array(cleaned.pred)\r\n",
        "\r\n",
        "conf = confusion_matrix(true_values, predictions)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def recall(conf, classname):\r\n",
        "    results = {}\r\n",
        "    for key, value in classname.items():\r\n",
        "        results[key] = conf[value, value] / np.sum(conf[value, :])\r\n",
        "    return results\r\n",
        "\r\n",
        "def precision(conf, classname):\r\n",
        "    results = {}\r\n",
        "    for key, value in classname.items():\r\n",
        "        results[key] = conf[value, value] / np.sum(conf[:, value])\r\n",
        "    return results\r\n",
        "\r\n",
        "def f1(conf, classname):\r\n",
        "    rec = recall(conf, classname)\r\n",
        "    prec = precision(conf, classname)\r\n",
        "    results = {}\r\n",
        "    for key in rec:\r\n",
        "        results[key] = (2*prec[key]*rec[key]) / (prec[key]+rec[key])\r\n",
        "    return results\r\n",
        "\r\n",
        "classname = {\r\n",
        "    \"Loss\": 0,\r\n",
        "    \"Draw\": 1,\r\n",
        "    \"Win\": 2\r\n",
        "} \r\n",
        "\r\n",
        "recall(conf, classname)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "precision(conf, classname)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "f1(conf, classname)"
      ],
      "outputs": [],
      "metadata": {}
    }
  ]
}